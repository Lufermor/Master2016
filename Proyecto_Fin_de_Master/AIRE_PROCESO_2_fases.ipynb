{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Limpieza de datos históricos de calidad del aire\n",
    "\n",
    "### En este archivo se leen datos en bruto obtenidos del portal de datos abiertos del ayuntamiento de Madrid, se limpian y se enriquecen con datos de estaciones de tráfico, para su posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "import pymongo \n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pandas.io.json import json_normalize\n",
    "import zipfile\n",
    "from datetime import date, datetime, timedelta\n",
    "import time\n",
    "from dateutil.parser import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rutas\n",
    "##### Se almacenan en variables, las rutas de las carpetas donde se encuentran los archivos sobre calidad del aire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PATH = \"./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015\"\n",
    "aire_historico_2015 = \"./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015\"\n",
    "aire_historico_2016 = \"./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016\"\n",
    "aire_historico_2017 = \"./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2017\"\n",
    "\n",
    "\n",
    "estaciones = \"./EnriquecimientoTrafico-CalidadAire.csv\"    # sep = ;\n",
    "estacionesInfo =\"./informacion_estaciones_red_calidad_aire.xls\"\n",
    "\n",
    "ruta_magnitud_Tecnica = \"./interprete.xlsx\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_files(path):\n",
    "    \"\"\"\n",
    "    Función que dada una ruta a una carpeta de archivos, devuelve una lista con las rutas a cada uno de los ficheros en la carpeta\n",
    "    \n",
    "    input: directorio donde están los ficheros zip de un año. Uno por  mes\n",
    "    output: devuelve la lista de los ficheros de cada mes\n",
    "    \"\"\"\n",
    "    return [ path +'/' + f for f in listdir(path) ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobación de existencia de ficheros mensuales históricos\n",
    "\n",
    "##### Utilizando la función extract_files definida previamente, se comprueba que los ficheros dentro de las carpetas son los correctos, estos archivos son datsets históricos de calidad del aire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Abril2015.xlsx\n",
      "1 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Agosto2015.xlsx\n",
      "2 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Dic2015.xlsx\n",
      "3 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Enero2015.xlsx\n",
      "4 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Febrero2015.xlsx\n",
      "5 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Julio2015.xlsx\n",
      "6 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Junio2015.xlsx\n",
      "7 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Marzo2015.xlsx\n",
      "8 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Mayo2015.xlsx\n",
      "9 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Nov2015.xlsx\n",
      "10 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Octubre2015.xlsx\n",
      "11 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2015/HistoricoHorario-CalidadAire-Sept2015.xlsx\n"
     ]
    }
   ],
   "source": [
    "## 2015\n",
    "#---------------------------------------------------------------------------\n",
    "# proceso de validación de los ficheros\n",
    "# comprobar que dentro haya un fichero XLSX por cada mes\n",
    "#---------------------------------------------------------------------------\n",
    "monthfiles_2015 = extract_files(aire_historico_2015)\n",
    "for i , file in enumerate(monthfiles_2015):     \n",
    "    print(i, \"-\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Abril2016.xlsx\n",
      "1 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Agosto2016.xlsx\n",
      "2 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Dic2016.xlsx\n",
      "3 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Enero2016.xlsx\n",
      "4 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Febrero2016.xlsx\n",
      "5 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Julio2016.xlsx\n",
      "6 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Junio2016.xlsx\n",
      "7 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Marzo2016.xlsx\n",
      "8 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Mayo2016.xlsx\n",
      "9 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Nov2016.xlsx\n",
      "10 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Octubre2016.xlsx\n",
      "11 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2016/HistoricoHorario-CalidadAire-Sept2016.xlsx\n"
     ]
    }
   ],
   "source": [
    "## 2016\n",
    "#---------------------------------------------------------------------------\n",
    "# proceso de validación de los ficheros\n",
    "# comprobar que dentro haya un fichero XLSX por cada mes\n",
    "#---------------------------------------------------------------------------\n",
    "monthfiles_2016 = extract_files(aire_historico_2016)\n",
    "for i , file in enumerate(monthfiles_2016):     \n",
    "    print(i, \"-\", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2017/2017-Enero-HistoricoHorario-CalidadAire.xlsx\n",
      "1 - ./DATASETS_AIRE/HistoricoHorarios-CalidadAire-2017/2017-Febrero-HistoricoHorario-CalidadAire.xlsx\n"
     ]
    }
   ],
   "source": [
    "## 2017\n",
    "#---------------------------------------------------------------------------\n",
    "# proceso de validación de los ficheros\n",
    "# comprobar que dentro haya un fichero XLSX por cada mes\n",
    "#---------------------------------------------------------------------------\n",
    "monthfiles_2017 = extract_files(aire_historico_2017)\n",
    "for i , file in enumerate(monthfiles_2017):     \n",
    "    print(i, \"-\", file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriquecimiento: \n",
    "##### A continuación se carga en un DataSet las distancias de las estaciones de tráfico a las de calidad del aire, y se enriquece la información de las estaciones de calidad del aire indicando si hay estaciones de tráfico en unos radios determinados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distancias entre estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codigoEst</th>\n",
       "      <th>estacion</th>\n",
       "      <th>cod_cent</th>\n",
       "      <th>nombre</th>\n",
       "      <th>Distacia EstAire-EstTraf</th>\n",
       "      <th>Ranking(el más cercano)</th>\n",
       "      <th>sum100</th>\n",
       "      <th>sum250</th>\n",
       "      <th>sum500</th>\n",
       "      <th>sum1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>16006</td>\n",
       "      <td>Pl. Espa a N-S - San Leonardo-Cuesta San Vicente</td>\n",
       "      <td>573.815.289.844</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>16041</td>\n",
       "      <td>(TACTICO) Pl. Espa-a (Salida del Aparcamiento)...</td>\n",
       "      <td>701.060.111.109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>16008</td>\n",
       "      <td>Pl. Espa a S-N - Reyes-San Leonardo</td>\n",
       "      <td>977.035.393.033</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>16007</td>\n",
       "      <td>Cuesta San Vicente O-E - Gran Via-Ferraz</td>\n",
       "      <td>102.306.925.836</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>16005</td>\n",
       "      <td>San Leonardo E-O - Maestro Guerrero-Princesa</td>\n",
       "      <td>1.314.466.851.072</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codigoEst        estacion cod_cent  \\\n",
       "0   28079004  Pza. de España    16006   \n",
       "1   28079004  Pza. de España    16041   \n",
       "2   28079004  Pza. de España    16008   \n",
       "3   28079004  Pza. de España    16007   \n",
       "4   28079004  Pza. de España    16005   \n",
       "\n",
       "                                              nombre Distacia EstAire-EstTraf  \\\n",
       "0   Pl. Espa a N-S - San Leonardo-Cuesta San Vicente          573.815.289.844   \n",
       "1  (TACTICO) Pl. Espa-a (Salida del Aparcamiento)...          701.060.111.109   \n",
       "2                Pl. Espa a S-N - Reyes-San Leonardo          977.035.393.033   \n",
       "3           Cuesta San Vicente O-E - Gran Via-Ferraz          102.306.925.836   \n",
       "4       San Leonardo E-O - Maestro Guerrero-Princesa        1.314.466.851.072   \n",
       "\n",
       "   Ranking(el más cercano)  sum100  sum250  sum500  sum1000  \n",
       "0                        1       1       1       1        1  \n",
       "1                        2       1       1       1        1  \n",
       "2                        3       1       1       1        1  \n",
       "3                        4       0       1       1        1  \n",
       "4                        5       0       1       1        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distancias estaciones contaminación - Trafico\n",
    "df_distEstTraf = pd.read_csv(estaciones , sep = ';', encoding='latin-1')\n",
    "# Se modifica el codigoEst, ya que viene en diferente formato en los ficheros\n",
    "df_distEstTraf[\"codigoEst\"] = df_distEstTraf[\"codigoEst\"] + 28079000\n",
    "df_distEstTraf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92832 entries, 0 to 92831\n",
      "Data columns (total 10 columns):\n",
      "codigoEst                   92832 non-null int64\n",
      "estacion                    92832 non-null object\n",
      "cod_cent                    92832 non-null object\n",
      "nombre                      92832 non-null object\n",
      "Distacia EstAire-EstTraf    92832 non-null object\n",
      "Ranking(el más cercano)     92832 non-null int64\n",
      "sum100                      92832 non-null int64\n",
      "sum250                      92832 non-null int64\n",
      "sum500                      92832 non-null int64\n",
      "sum1000                     92832 non-null int64\n",
      "dtypes: int64(6), object(4)\n",
      "memory usage: 7.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_distEstTraf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se leen los datos de las distancias y se convierten a json para tratarlos como diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "solution2": "shown",
    "solution2_first": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Distacia EstAire-EstTraf': '573.815.289.844',\n",
       "  'Ranking(el más cercano)': 1,\n",
       "  'cod_cent': '16006',\n",
       "  'codigoEst': 28079004,\n",
       "  'estacion': 'Pza. de España',\n",
       "  'nombre': 'Pl. Espa a N-S - San Leonardo-Cuesta San Vicente',\n",
       "  'sum100': 1,\n",
       "  'sum1000': 1,\n",
       "  'sum250': 1,\n",
       "  'sum500': 1},\n",
       " {'Distacia EstAire-EstTraf': '701.060.111.109',\n",
       "  'Ranking(el más cercano)': 2,\n",
       "  'cod_cent': '16041',\n",
       "  'codigoEst': 28079004,\n",
       "  'estacion': 'Pza. de España',\n",
       "  'nombre': '(TACTICO) Pl. Espa-a (Salida del Aparcamiento) - (TACTICO) Pl. Espana (Salida del Aparcamiento)',\n",
       "  'sum100': 1,\n",
       "  'sum1000': 1,\n",
       "  'sum250': 1,\n",
       "  'sum500': 1},\n",
       " {'Distacia EstAire-EstTraf': '977.035.393.033',\n",
       "  'Ranking(el más cercano)': 3,\n",
       "  'cod_cent': '16008',\n",
       "  'codigoEst': 28079004,\n",
       "  'estacion': 'Pza. de España',\n",
       "  'nombre': 'Pl. Espa a S-N - Reyes-San Leonardo',\n",
       "  'sum100': 1,\n",
       "  'sum1000': 1,\n",
       "  'sum250': 1,\n",
       "  'sum500': 1},\n",
       " {'Distacia EstAire-EstTraf': '102.306.925.836',\n",
       "  'Ranking(el más cercano)': 4,\n",
       "  'cod_cent': '16007',\n",
       "  'codigoEst': 28079004,\n",
       "  'estacion': 'Pza. de España',\n",
       "  'nombre': 'Cuesta San Vicente O-E - Gran Via-Ferraz',\n",
       "  'sum100': 0,\n",
       "  'sum1000': 1,\n",
       "  'sum250': 1,\n",
       "  'sum500': 1},\n",
       " {'Distacia EstAire-EstTraf': '1.314.466.851.072',\n",
       "  'Ranking(el más cercano)': 5,\n",
       "  'cod_cent': '16005',\n",
       "  'codigoEst': 28079004,\n",
       "  'estacion': 'Pza. de España',\n",
       "  'nombre': 'San Leonardo E-O - Maestro Guerrero-Princesa',\n",
       "  'sum100': 0,\n",
       "  'sum1000': 1,\n",
       "  'sum250': 1,\n",
       "  'sum500': 1}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = df_distEstTraf.to_json(orient='records', date_format = 'iso')\n",
    "data_json = json.loads(d)\n",
    "data_json[0: 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se genera un diccionario donde la clave es la estación, el valor es otro diccionario con cuatro claves: 'sum100', 'sum250', 'sum500' y 'sum1000' con valores de 0 o 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codEst = df_distEstTraf[\"codigoEst\"].values\n",
    "distancias = {}\n",
    "codEst = df_distEstTraf[\"codigoEst\"].values\n",
    "for e in codEst:\n",
    "    distancias[e] =  {'sum100':[], 'sum1000':[], 'sum250':[], 'sum500':[]}\n",
    "for d in data_json:\n",
    "    est = d['codigoEst']\n",
    "    cen = d['cod_cent']        \n",
    "    if d['sum100'] == 1:\n",
    "        distancias[est]['sum100'].append(cen)\n",
    "    if d['sum1000'] == 1:\n",
    "        distancias[est]['sum1000'].append(cen)\n",
    "    if d['sum250'] == 1:\n",
    "        distancias[est]['sum250'].append(cen)\n",
    "    if d['sum500'] == 1:\n",
    "        distancias[est]['sum500'].append(cen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Información de estaciones contaminación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>NÚMERO</th>\n",
       "      <th>ESTACIÓN</th>\n",
       "      <th>DIRECCIÓN</th>\n",
       "      <th>LONGITUD</th>\n",
       "      <th>LATITUD</th>\n",
       "      <th>Xcoord</th>\n",
       "      <th>Ycoord</th>\n",
       "      <th>ALTITUD</th>\n",
       "      <th>TIPO ESTACION *</th>\n",
       "      <th>...</th>\n",
       "      <th>BTX</th>\n",
       "      <th>HC</th>\n",
       "      <th>UV</th>\n",
       "      <th>VV</th>\n",
       "      <th>DV</th>\n",
       "      <th>TMP</th>\n",
       "      <th>HR</th>\n",
       "      <th>PRB</th>\n",
       "      <th>RS</th>\n",
       "      <th>LL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>Plaza de España</td>\n",
       "      <td>3º 42' 44,09''O</td>\n",
       "      <td>40º 25' 25,87''N</td>\n",
       "      <td>-3.712247</td>\n",
       "      <td>40.423853</td>\n",
       "      <td>635.0</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>Escuelas Aguirre</td>\n",
       "      <td>Entre C/ Alcalá y C/ O’ Donell</td>\n",
       "      <td>3º 40' 56,35''O</td>\n",
       "      <td>40º 25' 17,63''N</td>\n",
       "      <td>-3.682319</td>\n",
       "      <td>40.421564</td>\n",
       "      <td>670.0</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>X</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>Avda. Ramón y Cajal</td>\n",
       "      <td>Avda. Ramón y Cajal  esq. C/ Príncipe de Vergara</td>\n",
       "      <td>3º 40' 38,48''O</td>\n",
       "      <td>40º 27' 05,31''N</td>\n",
       "      <td>-3.677356</td>\n",
       "      <td>40.451475</td>\n",
       "      <td>708.0</td>\n",
       "      <td>UT</td>\n",
       "      <td>...</td>\n",
       "      <td>X</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>Arturo Soria</td>\n",
       "      <td>C/ Arturo Soria  esq. C/  Vizconde de los Asilos</td>\n",
       "      <td>3º 38' 21,24''O</td>\n",
       "      <td>40º 26' 24,17''N</td>\n",
       "      <td>-3.639233</td>\n",
       "      <td>40.440047</td>\n",
       "      <td>693.0</td>\n",
       "      <td>UF</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>Villaverde</td>\n",
       "      <td>C/. Juan Peñalver</td>\n",
       "      <td>3º 42' 47,96''O</td>\n",
       "      <td>40º 20' 49,70''N</td>\n",
       "      <td>-3.713322</td>\n",
       "      <td>40.347139</td>\n",
       "      <td>604.0</td>\n",
       "      <td>UF</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 NÚMERO             ESTACIÓN  \\\n",
       "0         NaN      4       Pza. de España   \n",
       "1         NaN      8     Escuelas Aguirre   \n",
       "2         NaN     11  Avda. Ramón y Cajal   \n",
       "3         NaN     16         Arturo Soria   \n",
       "4         NaN     17           Villaverde   \n",
       "\n",
       "                                           DIRECCIÓN         LONGITUD  \\\n",
       "0                                    Plaza de España  3º 42' 44,09''O   \n",
       "1                    Entre C/ Alcalá y C/ O’ Donell   3º 40' 56,35''O   \n",
       "2   Avda. Ramón y Cajal  esq. C/ Príncipe de Vergara  3º 40' 38,48''O   \n",
       "3  C/ Arturo Soria  esq. C/  Vizconde de los Asilos   3º 38' 21,24''O   \n",
       "4                                  C/. Juan Peñalver  3º 42' 47,96''O   \n",
       "\n",
       "            LATITUD    Xcoord     Ycoord  ALTITUD TIPO ESTACION * ...   BTX  \\\n",
       "0  40º 25' 25,87''N -3.712247  40.423853    635.0              UT ...   NaN   \n",
       "1  40º 25' 17,63''N -3.682319  40.421564    670.0              UT ...     X   \n",
       "2  40º 27' 05,31''N -3.677356  40.451475    708.0              UT ...     X   \n",
       "3  40º 26' 24,17''N -3.639233  40.440047    693.0              UF ...   NaN   \n",
       "4  40º 20' 49,70''N -3.713322  40.347139    604.0              UF ...   NaN   \n",
       "\n",
       "    HC   UV   VV   DV  TMP   HR  PRB   RS   LL  \n",
       "0  NaN  NaN    X    X    X    X  NaN  NaN    X  \n",
       "1    X  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN    X  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN    X  \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_estacionesInfo = pd.read_excel(estacionesInfo,  skiprows = 4)\n",
    "def_estacionesInfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordenadas de las estaciones de contaminación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NÚMERO</th>\n",
       "      <th>ESTACIÓN</th>\n",
       "      <th>Xcoord</th>\n",
       "      <th>Ycoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56</td>\n",
       "      <td>Pza. Fernández Ladreda</td>\n",
       "      <td>-3.718728</td>\n",
       "      <td>40.384964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>57</td>\n",
       "      <td>Sanchinarro</td>\n",
       "      <td>-3.660503</td>\n",
       "      <td>40.494208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>58</td>\n",
       "      <td>El Pardo</td>\n",
       "      <td>-3.774611</td>\n",
       "      <td>40.518058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>59</td>\n",
       "      <td>Juan Carlos I</td>\n",
       "      <td>-3.609072</td>\n",
       "      <td>40.465250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>Tres Olivos</td>\n",
       "      <td>-3.689761</td>\n",
       "      <td>40.500589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    NÚMERO                ESTACIÓN    Xcoord     Ycoord\n",
       "19      56  Pza. Fernández Ladreda -3.718728  40.384964\n",
       "20      57             Sanchinarro -3.660503  40.494208\n",
       "21      58                El Pardo -3.774611  40.518058\n",
       "22      59           Juan Carlos I -3.609072  40.465250\n",
       "23      60             Tres Olivos -3.689761  40.500589"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coor_estaciones = pd.read_excel(estacionesInfo,  skiprows = 4, \n",
    "                                  parse_cols = [1, 2, 6, 7] , skip_footer=4,\n",
    "                                  )\n",
    "df_coor_estaciones.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A continuación se edita el número de identificación de las estaciones para que coincida con los demás documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24 entries, 0 to 23\n",
      "Data columns (total 4 columns):\n",
      "NÚMERO      24 non-null int64\n",
      "ESTACIÓN    24 non-null object\n",
      "Xcoord      24 non-null float64\n",
      "Ycoord      24 non-null float64\n",
      "dtypes: float64(2), int64(1), object(1)\n",
      "memory usage: 848.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# el código de estación lo almacenao como 28079000 + número \n",
    "df_coor_estaciones[\"NÚMERO\"] = df_coor_estaciones[\"NÚMERO\"].apply(int)\n",
    "df_coor_estaciones[\"NÚMERO\"] = df_coor_estaciones[\"NÚMERO\"] + 28079000\n",
    "df_coor_estaciones.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NÚMERO</th>\n",
       "      <th>ESTACIÓN</th>\n",
       "      <th>Xcoord</th>\n",
       "      <th>Ycoord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>-3.712247</td>\n",
       "      <td>40.423853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28079008</td>\n",
       "      <td>Escuelas Aguirre</td>\n",
       "      <td>-3.682319</td>\n",
       "      <td>40.421564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28079011</td>\n",
       "      <td>Avda. Ramón y Cajal</td>\n",
       "      <td>-3.677356</td>\n",
       "      <td>40.451475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28079016</td>\n",
       "      <td>Arturo Soria</td>\n",
       "      <td>-3.639233</td>\n",
       "      <td>40.440047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28079017</td>\n",
       "      <td>Villaverde</td>\n",
       "      <td>-3.713322</td>\n",
       "      <td>40.347139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NÚMERO             ESTACIÓN    Xcoord     Ycoord\n",
       "0  28079004       Pza. de España -3.712247  40.423853\n",
       "1  28079008     Escuelas Aguirre -3.682319  40.421564\n",
       "2  28079011  Avda. Ramón y Cajal -3.677356  40.451475\n",
       "3  28079016         Arturo Soria -3.639233  40.440047\n",
       "4  28079017           Villaverde -3.713322  40.347139"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coor_estaciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 1  - Proceso 2015 - 2016 - 2017 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta fase se generan ficheros de tipo CSV enriquecidos con los siguientes datos:\n",
    "* Fecha\n",
    "* Coordenadas\n",
    "* Magnitud técnica, etc\n",
    "\n",
    "En la fase 2 se realiza el enriquecimiento de la intensidad de tráfico.\n",
    "* Lectura de los ficheros enriquecidos en la fase 1\n",
    "* Lectura de los datos enriquecidos de tráfico\n",
    "* Generación de ficheros CSV de aire totalmente enriquecidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# función para convertir a fecha datetime la fecha que llega del fichero\n",
    "def todate(x):\n",
    "    int(x)\n",
    "    year = (x // 10000) + 2000\n",
    "    month = (x // 100) % 100\n",
    "    day = x % 100\n",
    "    return datetime(year, month, day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# función para convertir a fecha datetime la fecha que llega del fichero\n",
    "def totimestamp(x):\n",
    "    int(x)\n",
    "    year = (x // 10000) + 2000\n",
    "    month = (x // 100) % 100\n",
    "    day = x % 100\n",
    "    return pd.Timestamp(datetime(year, month, day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Función que transforma las unidades de hora que se suman en  tipo timedelta\n",
    "def gethora(d, serie):\n",
    "    return pd.to_timedelta(serie.map(d), unit = 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitudCod</th>\n",
       "      <th>magnitudNombre</th>\n",
       "      <th>Formula</th>\n",
       "      <th>tecnicaCod</th>\n",
       "      <th>tecnicaNom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dióxido de Azufre</td>\n",
       "      <td>SO2</td>\n",
       "      <td>38</td>\n",
       "      <td>Fluorescencia ultravioleta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Monóxido de Carbono</td>\n",
       "      <td>CO2</td>\n",
       "      <td>48</td>\n",
       "      <td>Absorción infrarroja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Monóxido de Nitrógeno</td>\n",
       "      <td>NO</td>\n",
       "      <td>8</td>\n",
       "      <td>Quimioluminiscencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Dióxido de Nitrógeno</td>\n",
       "      <td>NO2</td>\n",
       "      <td>8</td>\n",
       "      <td>Quimioluminiscencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>Óxidos de Nitrógeno</td>\n",
       "      <td>Nox</td>\n",
       "      <td>8</td>\n",
       "      <td>Quimioluminiscencia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>Partículas &lt; 2.5 µm</td>\n",
       "      <td>PM2.5</td>\n",
       "      <td>47</td>\n",
       "      <td>Microbalanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>Partículas &lt; 10 µm</td>\n",
       "      <td>PM10</td>\n",
       "      <td>47</td>\n",
       "      <td>Microbalanza</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>Ozono</td>\n",
       "      <td>O3</td>\n",
       "      <td>6</td>\n",
       "      <td>Absorción ultravioleta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>Tolueno</td>\n",
       "      <td>TOL</td>\n",
       "      <td>59</td>\n",
       "      <td>Cromatografía de gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30</td>\n",
       "      <td>Benceno</td>\n",
       "      <td>BEN</td>\n",
       "      <td>59</td>\n",
       "      <td>Cromatografía de gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>35</td>\n",
       "      <td>Etilbenceno</td>\n",
       "      <td>EBE</td>\n",
       "      <td>59</td>\n",
       "      <td>Cromatografía de gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>37</td>\n",
       "      <td>Metaxileno</td>\n",
       "      <td>MXY</td>\n",
       "      <td>59</td>\n",
       "      <td>Cromatografía de gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38</td>\n",
       "      <td>Paraxileno</td>\n",
       "      <td>PXY</td>\n",
       "      <td>59</td>\n",
       "      <td>Cromatografía de gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>39</td>\n",
       "      <td>Ortoxileno</td>\n",
       "      <td>OXY</td>\n",
       "      <td>59</td>\n",
       "      <td>Cromatografía de gases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>42</td>\n",
       "      <td>Hidrocarburos totales (hexano)</td>\n",
       "      <td>TCH</td>\n",
       "      <td>2</td>\n",
       "      <td>Ionización de llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>44</td>\n",
       "      <td>Hidrocarburos no metánicos (hexano)</td>\n",
       "      <td>NMHC</td>\n",
       "      <td>2</td>\n",
       "      <td>Ionización de llama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    magnitudCod                       magnitudNombre Formula  tecnicaCod  \\\n",
       "0             1                    Dióxido de Azufre     SO2          38   \n",
       "1             6                 Monóxido de Carbono      CO2          48   \n",
       "2             7               Monóxido de Nitrógeno       NO           8   \n",
       "3             8                Dióxido de Nitrógeno      NO2           8   \n",
       "4            12                  Óxidos de Nitrógeno     Nox           8   \n",
       "5             9                  Partículas < 2.5 µm   PM2.5          47   \n",
       "6            10                   Partículas < 10 µm    PM10          47   \n",
       "7            14                               Ozono       O3           6   \n",
       "8            20                             Tolueno      TOL          59   \n",
       "9            30                              Benceno     BEN          59   \n",
       "10           35                         Etilbenceno      EBE          59   \n",
       "11           37                          Metaxileno      MXY          59   \n",
       "12           38                          Paraxileno      PXY          59   \n",
       "13           39                          Ortoxileno      OXY          59   \n",
       "14           42      Hidrocarburos totales (hexano)      TCH           2   \n",
       "15           44  Hidrocarburos no metánicos (hexano)    NMHC           2   \n",
       "\n",
       "                    tecnicaNom  \n",
       "0   Fluorescencia ultravioleta  \n",
       "1        Absorción infrarroja   \n",
       "2         Quimioluminiscencia   \n",
       "3         Quimioluminiscencia   \n",
       "4         Quimioluminiscencia   \n",
       "5                Microbalanza   \n",
       "6                Microbalanza   \n",
       "7       Absorción ultravioleta  \n",
       "8       Cromatografía de gases  \n",
       "9       Cromatografía de gases  \n",
       "10      Cromatografía de gases  \n",
       "11      Cromatografía de gases  \n",
       "12      Cromatografía de gases  \n",
       "13      Cromatografía de gases  \n",
       "14        Ionización de llama   \n",
       "15        Ionización de llama   "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mag = pd.read_excel(ruta_magnitud_Tecnica ,sheetname = 0)\n",
    "tec = pd.read_excel(ruta_magnitud_Tecnica ,sheetname = 1)\n",
    "magtec = pd.merge(mag,tec, on=['tecnicaCod'])\n",
    "magtec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A continuación se hace un bucle sobre los ficheros correspondientes a los meses de cada año.\n",
    "#### Se extraen las horas por día y los valores que les corresponden, los valores se modifican ligeramente y se vuelven a añadir a la matriz del mes. Se da formato a las fechas, se añaden las coordenadas y la información de la magnitud técnica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Año 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for mesxlsx in monthfiles_2017:\n",
    "    month = pd.read_excel(mesxlsx)\n",
    "    d2 = month.iloc[:,-24:].to_json(orient = \"index\")\n",
    "    d2 = json.loads(d2)\n",
    "    m = []\n",
    "    for indice, v in d2.items():\n",
    "        for h, mh in v.items():\n",
    "            m.append( [int(indice), h, mh] )   \n",
    "    # Se crea el tataframe a partir de m    \n",
    "    df = pd.DataFrame(m, columns = ['indice', \"hora\", \"valor\"] )\n",
    "    df.valor = df.valor.map(lambda x: x.replace('V', ''))\n",
    "    month1 = pd.merge(df, month.iloc[:,:-24], left_on = 'indice',\n",
    "                          right_index = True)\n",
    "    # Se transforma Año+Mes+Dia\n",
    "    month1.AnoMesDia = month1.AnoMesDia.map(totimestamp)\n",
    "    horas = dict(zip(list(month.iloc[:,-24:].columns), range(1, 25)))\n",
    "    month1[\"fechaHora\"] = gethora(horas, month1.hora) + month1.AnoMesDia\n",
    "    # Se añaden las coordenadas\n",
    "    month2 = pd.merge(month1, df_coor_estaciones, \n",
    "                      left_on = 'Estacion', \n",
    "                      right_on = 'NÚMERO')\n",
    "    # Se añade la información de la magnitud técnica\n",
    "    month3 = pd.merge(month2,magtec, left_on = 'Magnitud', right_on = 'magnitudCod')\n",
    "    month4 = month3.reindex(columns = ['Estacion', 'ESTACIÓN', 'Xcoord', 'Ycoord',\n",
    "                                  'fechaHora',  'Dato Horario', \"magnitudCod\",\n",
    "                                  \"magnitudNombre\", \n",
    "                                  'tecnicaCod', 'tecnicaNom', 'valor'])\n",
    "    # guardo el dataframe en un fichero csv\n",
    "    t = month4.fechaHora[0]\n",
    "    tofile = './procesados-Prev/' + str(t)[5:7] + '-' +  str(t.year) + '.csv'\n",
    "    month4.to_csv(tofile, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Año 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for mesxlsx in monthfiles_2016:\n",
    "    month = pd.read_excel(mesxlsx)\n",
    "    d2 = month.iloc[:,-24:].to_json(orient = \"index\")\n",
    "    d2 = json.loads(d2)\n",
    "    m = []\n",
    "    for indice, v in d2.items():\n",
    "        for h, mh in v.items():\n",
    "            m.append( [int(indice), h, mh] )   \n",
    "    # Se crea el tataframe a partir de m    \n",
    "    df = pd.DataFrame(m, columns = ['indice', \"hora\", \"valor\"] )\n",
    "    df.valor = df.valor.map(lambda x: x.replace('V', ''))\n",
    "    month1 = pd.merge(df, month.iloc[:,:-24], left_on = 'indice',\n",
    "                          right_index = True)\n",
    "    # Se transforma Año+Mes+Dia\n",
    "    month1.AnoMesDia = month1.AnoMesDia.map(totimestamp)\n",
    "    horas = dict(zip(list(month.iloc[:,-24:].columns), range(1, 25)))\n",
    "    month1[\"fechaHora\"] = gethora(horas, month1.hora) + month1.AnoMesDia\n",
    "    \n",
    "    # Se añaden las coordenadas\n",
    "    month2 = pd.merge(month1, df_coor_estaciones, \n",
    "                      left_on = 'Estacion', \n",
    "                      right_on = 'NÚMERO')\n",
    "    \n",
    "    # Se añade la información de la magnitud técnica\n",
    "    month3 = pd.merge(month2,magtec, left_on = 'Magnitud', right_on = 'magnitudCod')\n",
    "    month4 = month3.reindex(columns = ['Estacion', 'ESTACIÓN', 'Xcoord', 'Ycoord',\n",
    "                                  'fechaHora',  'Dato Horario', \"magnitudCod\",\n",
    "                                  \"magnitudNombre\", \n",
    "                                  'tecnicaCod', 'tecnicaNom', 'valor'])\n",
    "    # guardo el dataframe en un fichero csv\n",
    "    t = month4.fechaHora[0]\n",
    "    tofile = './procesados-Prev/' + str(t)[5:7] + '-' +  str(t.year) + '.csv'\n",
    "    month4.to_csv(tofile, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Año 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for mesxlsx in monthfiles_2015:\n",
    "    month = pd.read_excel(mesxlsx)\n",
    "    d2 = month.iloc[:,-24:].to_json(orient = \"index\")\n",
    "    d2 = json.loads(d2)\n",
    "    m = []\n",
    "    for indice, v in d2.items():\n",
    "        for h, mh in v.items():\n",
    "            m.append( [int(indice), h, mh] )   \n",
    "    # Se crea el tataframe a partir de m    \n",
    "    df = pd.DataFrame(m, columns = ['indice', \"hora\", \"valor\"] )\n",
    "    df.valor = df.valor.map(lambda x: x.replace('V', ''))\n",
    "    month1 = pd.merge(df, month.iloc[:,:-24], left_on = 'indice',\n",
    "                          right_index = True)\n",
    "    # Se transforma Año+Mes+Dia\n",
    "    month1.AnoMesDia = month1.AnoMesDia.map(totimestamp)\n",
    "    horas = dict(zip(list(month.iloc[:,-24:].columns), range(1, 25)))\n",
    "    month1[\"fechaHora\"] = gethora(horas, month1.hora) + month1.AnoMesDia\n",
    "    \n",
    "    # Se añaden las coordenadas\n",
    "    month2 = pd.merge(month1, df_coor_estaciones, \n",
    "                      left_on = 'Estacion', \n",
    "                      right_on = 'NÚMERO')\n",
    "    \n",
    "    # Se añade la información de la magnitud técnica\n",
    "    month3 = pd.merge(month2,magtec, left_on = 'Magnitud', right_on = 'magnitudCod')\n",
    "    if len(month3) == 0:\n",
    "        continue\n",
    "    \n",
    "    month4 = month3.reindex(columns = ['Estacion', 'ESTACIÓN', 'Xcoord', 'Ycoord',\n",
    "                                  'fechaHora',  'Dato Horario', \"magnitudCod\",\n",
    "                                  \"magnitudNombre\", \n",
    "                                  'tecnicaCod', 'tecnicaNom', 'valor'])\n",
    "    # guardo el dataframe en un fichero csv\n",
    "    t = month4.fechaHora[0]\n",
    "    tofile = './procesados-Prev/' + str(t)[5:7] + '-' +  str(t.year) + '.csv'\n",
    "    month4.to_csv(tofile, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fase 2 : Intensidad de tráfico\n",
    "#### Por cada fichero de aire se abren dos ficheros de tráfico. Esto es porque la última hora de cada més  se corresponde al mes siguiente, por ejemplo: en el fichero 01-2015 se tienen los datos de enero y los datos asociados a la hora: 2015-02-01 00:00:00 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Función que dados un mes y año, devielve un nombre de archivo correspondientes a estos y al siguiente\n",
    "def buildNameFile(month, year):\n",
    "    \"\"\"\n",
    "    input: mes, año\n",
    "    Output: lista con nombre de archivo del mes dado y del mes siguiente.\n",
    "    \"\"\"\n",
    "    monthsig = month + 1\n",
    "    if monthsig == 13:\n",
    "        monthsig = 1\n",
    "        yearsig = year + 1\n",
    "    else:\n",
    "        yearsig = year\n",
    "    mes = datetime(year, month, 1)\n",
    "    messig= datetime(yearsig, monthsig, 1)\n",
    "    f = str(mes)[5:7] + '-' + str(mes)[:4] + '.csv'\n",
    " \n",
    "    fsig = str(messig)[5:7] + '-' + str(messig)[:4] + '.csv'\n",
    "    return [f, fsig]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RUTA FICHEROS PROCESADOS y enriquecidos en la fase 1\n",
    "ruta_procesados_aire = \"./procesados-Prev\"\n",
    "month_files = extract_files(ruta_procesados_aire)\n",
    "openTraf = {}\n",
    "for i , file in enumerate(month_files):   \n",
    "    mes= int( file[-11:-9])\n",
    "    year = int(file[-8:-4] )\n",
    "    openTraf[file] = buildNameFile(mes, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'./procesados-Prev/01-2015.csv': ['01-2015.csv', '02-2015.csv'],\n",
       " './procesados-Prev/01-2017.csv': ['01-2017.csv', '02-2017.csv'],\n",
       " './procesados-Prev/02-2015.csv': ['02-2015.csv', '03-2015.csv'],\n",
       " './procesados-Prev/02-2017.csv': ['02-2017.csv', '03-2017.csv'],\n",
       " './procesados-Prev/03-2015.csv': ['03-2015.csv', '04-2015.csv'],\n",
       " './procesados-Prev/05-2015.csv': ['05-2015.csv', '06-2015.csv'],\n",
       " './procesados-Prev/05-2016.csv': ['05-2016.csv', '06-2016.csv'],\n",
       " './procesados-Prev/06-2015.csv': ['06-2015.csv', '07-2015.csv'],\n",
       " './procesados-Prev/06-2016.csv': ['06-2016.csv', '07-2016.csv'],\n",
       " './procesados-Prev/07-2015.csv': ['07-2015.csv', '08-2015.csv'],\n",
       " './procesados-Prev/07-2016.csv': ['07-2016.csv', '08-2016.csv'],\n",
       " './procesados-Prev/08-2015.csv': ['08-2015.csv', '09-2015.csv'],\n",
       " './procesados-Prev/08-2016.csv': ['08-2016.csv', '09-2016.csv'],\n",
       " './procesados-Prev/09-2015.csv': ['09-2015.csv', '10-2015.csv'],\n",
       " './procesados-Prev/09-2016.csv': ['09-2016.csv', '10-2016.csv'],\n",
       " './procesados-Prev/10-2015.csv': ['10-2015.csv', '11-2015.csv'],\n",
       " './procesados-Prev/10-2016.csv': ['10-2016.csv', '11-2016.csv'],\n",
       " './procesados-Prev/11-2015.csv': ['11-2015.csv', '12-2015.csv'],\n",
       " './procesados-Prev/11-2016.csv': ['11-2016.csv', '12-2016.csv'],\n",
       " './procesados-Prev/12-2015.csv': ['12-2015.csv', '01-2016.csv'],\n",
       " './procesados-Prev/12-2016.csv': ['12-2016.csv', '01-2017.csv']}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lista de ficheros a abrir\n",
    "Por ejemplo, para enriquecer aire del mes de enero\n",
    "\"\"\"\n",
    "\n",
    "openTraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Funciones para calcular los niveles de intensidad\n",
    "\"\"\"\n",
    "\n",
    "def f100(row):\n",
    "    def inten(dfTrafico): \n",
    "        if bool(row['s100']):        \n",
    "            f1 = dfTrafico[dfTrafico.fecha == row['fechaHora']]\n",
    "            f2 = f1[ f1.identif.isin(row['s100'])].intensidad.sum()   \n",
    "            return f2 # float\n",
    "        else:\n",
    "            return 0\n",
    "    return inten\n",
    "\n",
    "def f1000(row):\n",
    "    def inten(dfTrafico):  \n",
    "        if bool(row['s1000']):\n",
    "        #f1 = dfTrafico[dfTrafico.identif.isin(row['s1000'])]\n",
    "            f1 = dfTrafico[dfTrafico.fecha == row['fechaHora']]\n",
    "        #print(len(f1)), print(len(f11))\n",
    "            f2 = f1[ f1.identif.isin(row['s1000'])].intensidad.sum()   \n",
    "            return f2\n",
    "        else:\n",
    "            return 0\n",
    "    return inten\n",
    "\n",
    "def f500(row):\n",
    "    def inten(dfTrafico): \n",
    "        if bool(row['s500']):        \n",
    "        #f1 = dfTrafico[dfTrafico.identif.isin(row['s1000'])]\n",
    "            f1 = dfTrafico[dfTrafico.fecha == row['fechaHora']]\n",
    "        #print(len(f1)), print(len(f11))\n",
    "            f2 = f1[ f1.identif.isin(row['s500'])].intensidad.sum()   \n",
    "            return f2 \n",
    "        else:\n",
    "            return 0\n",
    "    return inten\n",
    "\n",
    "def f250(row):\n",
    "    def inten(dfTrafico):\n",
    "        if bool(row['s250']):       \n",
    "        #f1 = dfTrafico[dfTrafico.identif.isin(row['s1000'])]\n",
    "            f1 = dfTrafico[dfTrafico.fecha == row['fechaHora']]\n",
    "        #print(len(f1)), print(len(f11))\n",
    "            f2 = f1[ f1.identif.isin(row['s250'])].intensidad.sum()   \n",
    "            return f2 \n",
    "        else:\n",
    "            return 0\n",
    "    return inten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Número de columnas a añadir al dataframe\n",
    "\"\"\"\n",
    "sdis = ['s100', 's1000','s250','s500' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12:09:02\n",
      "./procesados-Prev/01-2017.csv ['01-2017.csv', '02-2017.csv']\n",
      "./procesados-Prev/02-2017.csv ['02-2017.csv', '03-2017.csv']\n",
      "12:09:44\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Esta celda se ejecuta tres veces, una por año \n",
    "\"\"\"\n",
    "\n",
    "print (time.strftime('%H:%M:%S'))\n",
    "\n",
    "for mesxlsx in month_files:\n",
    "    # juego solo con los de 2017 \n",
    "    if  int(mesxlsx[-8:-4]) != 2017 :\n",
    "        continue\n",
    "    # juego solo con los de 2016\n",
    "    \"\"\"if  int(mesxlsx[-8:-4]) != 2016 :\n",
    "        continue\"\"\"\n",
    "    # juego solo con los de 2015\n",
    "    \"\"\"if  int(mesxlsx[-8:-4]) != 2015 :\n",
    "    continue\"\"\"\n",
    "    \n",
    "\n",
    "    month = pd.read_csv(mesxlsx,  encoding='latin-1', \n",
    "                          parse_dates = [4])\n",
    "    d4 = month.Estacion.map(distancias)\n",
    "    month['s100'] = d4.map(lambda x: x['sum100'])\n",
    "    month['s1000'] = d4.map(lambda x: x['sum1000'])\n",
    "    month['s250'] = d4.map(lambda x: x['sum250'])\n",
    "    month['s500'] = d4.map(lambda x: x['sum500'])\n",
    "    # ficheros de tráfico a consultar:\n",
    "    files_intensidad = openTraf[mesxlsx]\n",
    "    print(mesxlsx, files_intensidad)\n",
    "    try:\n",
    "        df_traf = pd.read_csv('../TRAFICO/procesados/' + files_intensidad[0], \n",
    "               parse_dates = [1], \n",
    "               usecols = [1,2, 4])   \n",
    "        df_traf.fecha = df_traf.fecha.map(lambda x: pd.Timestamp(x))\n",
    "    except:\n",
    "        print(\"file 1 do not exist\")\n",
    "        continue\n",
    "    #m1.idelem = m1.idelem.map(lambda x : str(x))\n",
    "    if len(files_intensidad) == 2:\n",
    "        try:\n",
    "            m2 = pd.read_csv('../TRAFICO/procesados/' + files_intensidad[1], \n",
    "               parse_dates = [1], \n",
    "               usecols = [1,2, 4])\n",
    "            m2.fecha = m2.fecha.map(lambda x: pd.Timestamp(x))\n",
    "        except:\n",
    "            print(\"file 2 do not exist\")\n",
    "            continue\n",
    "        #m2.idelem = m2.idelem.map(lambda x : str(x))\n",
    "        \n",
    "        df_traf = pd.concat([df_traf, m2], ignore_index = True)\n",
    "        \n",
    "    # completo con las intensidades\n",
    "    # tarda 15 minutos por columna (1 hora por mes)\n",
    "    # INTENSIDAD D100 ----\n",
    "    print (time.strftime('%H:%M:%S'), 's100')\n",
    "    sdis = ['s100']\n",
    "    month['s100'] = d4.map(lambda x: x['sum100'])\n",
    "    serief100 = month.apply(f100, axis = 1)   # serie de funciones\n",
    "    month['d100'] = serief100.map(lambda x: x(df_traf))   # nueva col. de tipo float\n",
    "    month.drop(sdis,axis=1, inplace = True)\n",
    "    print (time.strftime('%H:%M:%S'),  's1000')\n",
    "    # INTENSIDAD D1000 ----\n",
    "    sdis = ['s1000']\n",
    "    month['s1000'] = d4.map(lambda x: x['sum1000'])\n",
    "    serief1000 = month.apply(f1000, axis = 1)\n",
    "    month['d1000'] = serief1000.map(lambda x: x(df_traf))\n",
    "    month.drop(sdis,axis=1, inplace = True)\n",
    "    print (time.strftime('%H:%M:%S'),  's500')\n",
    "     # INTENSIDAD D500 ---\n",
    "    sdis = ['s500']\n",
    "    month['s500'] = d4.map(lambda x: x['sum500'])\n",
    "    serief500 = month.apply(f500, axis = 1)\n",
    "    month['d500'] = serief500.map(lambda x: x(df_traf))\n",
    "    month.drop(sdis,axis=1, inplace = True)\n",
    "    print (time.strftime('%H:%M:%S'),  's250')        \n",
    "    #· INTENSIDAD D250 --------\n",
    "    sdis = ['s250'] \n",
    "    month['s250'] = d4.map(lambda x: x['sum250'])\n",
    "    serief250 = month.apply(f250, axis = 1)\n",
    "    month['d250'] = serief250.map(lambda x: x(df_traf))\n",
    "    month.drop(sdis,axis=1, inplace = True)\n",
    "    print (time.strftime('%H:%M:%S'),  'fin intensidad')\n",
    "        \n",
    "    # guardar en un csv    \n",
    "    savefile = mesxlsx.replace('Prev', 'inten')\n",
    "    month.to_csv(savefile, index = False)\n",
    "    \n",
    "    \n",
    "print(time.strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Volcado de ficheros csv a Mongo ( fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MONGO\n",
    "def open_conection():\n",
    "    client = pymongo.MongoClient('localhost',27017)\n",
    "    return client\n",
    "\n",
    "def storeTrafico(col, tabla):\n",
    "    d = tabla.to_json(orient='records', date_format = 'iso')\n",
    "    data_json = json.loads(d)\n",
    "    print(data_json[0])\n",
    "    for d in data_json:\n",
    "        d['fechaHora']= parse(d['fechaHora'])\n",
    "    col.insert_many(data_json) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./procesados-inten/01-2015.csv',\n",
       " './procesados-inten/01-2016.csv',\n",
       " './procesados-inten/01-2017.csv',\n",
       " './procesados-inten/02-2015.csv',\n",
       " './procesados-inten/02-2016.csv',\n",
       " './procesados-inten/02-2017.csv',\n",
       " './procesados-inten/03-2015.csv',\n",
       " './procesados-inten/03-2016.csv',\n",
       " './procesados-inten/04-2016.csv',\n",
       " './procesados-inten/05-2015.csv',\n",
       " './procesados-inten/05-2016.csv',\n",
       " './procesados-inten/06-2015.csv',\n",
       " './procesados-inten/06-2016.csv',\n",
       " './procesados-inten/07-2015.csv',\n",
       " './procesados-inten/07-2016.csv',\n",
       " './procesados-inten/08-2015.csv',\n",
       " './procesados-inten/08-2016.csv',\n",
       " './procesados-inten/09-2015.csv',\n",
       " './procesados-inten/09-2016.csv',\n",
       " './procesados-inten/10-2015.csv',\n",
       " './procesados-inten/10-2016.csv',\n",
       " './procesados-inten/11-2015.csv',\n",
       " './procesados-inten/11-2016.csv',\n",
       " './procesados-inten/12-2015.csv',\n",
       " './procesados-inten/12-2016.csv']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RUTA FICHEROS PROCESADOS\n",
    "ruta_enriquecidos_aire = \"./procesados-inten\"\n",
    "month_files_inten = extract_files(ruta_enriquecidos_aire)\n",
    "month_files_inten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True),\n",
       " Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'aire'))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = open_conection()\n",
    "db = client.aire\n",
    "client, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-01-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00016', 'intensidad100': 0.0, 'intensidad1000': 1515.75, 'intensidad500': 0.0, 'intensidad250': 0.0}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-02-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00006', 'intensidad100': 2022.5, 'intensidad1000': 52931.0, 'intensidad500': 21987.25, 'intensidad250': 12548.25}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-03-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00007', 'intensidad100': 1970.5, 'intensidad1000': 56629.5, 'intensidad500': 24330.5, 'intensidad250': 13816.5}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-05-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00005', 'intensidad100': 872.75, 'intensidad1000': 45773.1666666667, 'intensidad500': 19686.0, 'intensidad250': 10755.5}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-06-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00006', 'intensidad100': 1015.75, 'intensidad1000': 32756.25, 'intensidad500': 13934.5, 'intensidad250': 7631.4166666667}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-07-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00005', 'intensidad100': 1344.0, 'intensidad1000': 43379.4166666667, 'intensidad500': 16693.25, 'intensidad250': 9342.5}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-08-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00005', 'intensidad100': 1379.5, 'intensidad1000': 42902.25, 'intensidad500': 16878.5, 'intensidad250': 9045.5}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-09-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00008', 'intensidad100': 874.75, 'intensidad1000': 23622.75, 'intensidad500': 8966.25, 'intensidad250': 5388.25}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-10-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00010', 'intensidad100': 1380.75, 'intensidad1000': 40108.8333333333, 'intensidad500': 16043.75, 'intensidad250': 8511.25}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-11-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00006', 'intensidad100': 1900.25, 'intensidad1000': 61266.8333333333, 'intensidad500': 23116.5, 'intensidad250': 13235.5}\n",
      "{'codEstacion': 28079004, 'estacion': 'Pza. de España', 'Xcoord': -3.7122472222, 'Ycoord': 40.4238527778, 'fechaHora': '2015-12-01T01:00:00.000Z', 'Dato Horario': 2, 'magnitudCod': 1, 'magnitudNombre': 'Dióxido de Azufre', 'tecnicaCod': 38, 'tecnicaNom': 'Fluorescencia ultravioleta', 'valor': '00011', 'intensidad100': 759.0, 'intensidad1000': 28018.0, 'intensidad500': 10639.5, 'intensidad250': 5538.5}\n"
     ]
    }
   ],
   "source": [
    "col = db.aire2015\n",
    "#col.drop() # borro la colección entera\n",
    "for file in month_files_inten:   \n",
    "    # vuelvo los de de 2017 \n",
    "    #if  int(file[-8:-4]) != 2017 :\n",
    "    #    continue\n",
    "    \n",
    "    # juego solo con los de 2016\n",
    "    #if  int(file[-8:-4]) != 2016 :\n",
    "    #    continue\n",
    "    \n",
    "    # juego solo con los de 2015\n",
    "    if  int(file[-8:-4]) != 2015 :\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    month = pd.read_csv(file,  encoding='latin-1', parse_dates = [4])\n",
    "    old = month.columns\n",
    "    new = month.columns\n",
    "\n",
    "    names = dict(zip(old, new))\n",
    "    names['Estacion'] = 'codEstacion'\n",
    "    names['ESTACION'] = 'estacion'\n",
    "    names['ESTACIÓN'] = 'estacion'\n",
    "    names['d100'] = 'intensidad100'\n",
    "    names['d1000'] = 'intensidad1000'\n",
    "    names['d500'] = 'intensidad500'\n",
    "    names['d250'] = 'intensidad250'\n",
    "    month = month.rename(columns = names) \n",
    "\n",
    "    storeTrafico(col, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba para enriqueceser intensiad consultando mongo. Descartado. Tarda mucho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'trafico_timestamp'), 'trafico2017')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consultas a mongo\n",
    "def open_conection():\n",
    "    client = pymongo.MongoClient('localhost',27017)\n",
    "    return client\n",
    "\n",
    "client.close()\n",
    "client = open_conection()\n",
    "db = client.trafico_timestamp\n",
    "col2017 = db.trafico2017\n",
    "col2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estacion</th>\n",
       "      <th>ESTACIÓN</th>\n",
       "      <th>Xcoord</th>\n",
       "      <th>Ycoord</th>\n",
       "      <th>fechaHora</th>\n",
       "      <th>Dato Horario</th>\n",
       "      <th>magnitudCod</th>\n",
       "      <th>magnitudNombre</th>\n",
       "      <th>tecnicaCod</th>\n",
       "      <th>tecnicaNom</th>\n",
       "      <th>valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>-3.712247</td>\n",
       "      <td>40.423853</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dióxido de Azufre</td>\n",
       "      <td>38</td>\n",
       "      <td>Fluorescencia ultravioleta</td>\n",
       "      <td>00007V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28079004</td>\n",
       "      <td>Pza. de España</td>\n",
       "      <td>-3.712247</td>\n",
       "      <td>40.423853</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dióxido de Azufre</td>\n",
       "      <td>38</td>\n",
       "      <td>Fluorescencia ultravioleta</td>\n",
       "      <td>00006V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Estacion        ESTACIÓN    Xcoord     Ycoord           fechaHora  \\\n",
       "0  28079004  Pza. de España -3.712247  40.423853 2017-01-01 01:00:00   \n",
       "1  28079004  Pza. de España -3.712247  40.423853 2017-01-01 02:00:00   \n",
       "\n",
       "   Dato Horario  magnitudCod     magnitudNombre  tecnicaCod  \\\n",
       "0             2            1  Dióxido de Azufre          38   \n",
       "1             2            1  Dióxido de Azufre          38   \n",
       "\n",
       "                   tecnicaNom   valor  \n",
       "0  Fluorescencia ultravioleta  00007V  \n",
       "1  Fluorescencia ultravioleta  00006V  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month4.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sin agregado (esta funciona)\n",
    "def intensidad(coleccion, d4 , hora):\n",
    "    \"\"\"\n",
    "      input: colección donde hay qeu consultar\n",
    "             lista de estaciones de tráfico\n",
    "             e : estación que estamos enriqueciendo los datos\n",
    "             hora \n",
    "      output: nivel de intensidad\n",
    "    \"\"\"\n",
    "    res = {'sum100':0, 'sum250': 0, 'sum500':0, 'sum1000': 0}\n",
    "    listaIdent1000 = d4['sum1000']\n",
    "    if bool(listaIdent1000):  # si hay estaciones de tráfico cerca        \n",
    "        cursor = coleccion.find(\n",
    "                            {'identif' : { '$in': listaIdent1000},\n",
    "                            'fecha': {'$eq': hora}}    ,\n",
    "                     {'identif': 1, 'fecha': 1, 'intensidad':1})\n",
    "        if (cursor.alive) :  # si ha encontrado datos\n",
    "            # construyo el dataframe\n",
    "            df = pd.DataFrame(list(cursor))\n",
    "            res['sum100'] = df[df.identif.map(lambda x: x in d4['sum100'])].intensidad.sum()\n",
    "            res['sum250'] = df[df.identif.map(lambda x: x in d4['sum250'])].intensidad.sum()\n",
    "            res['sum500'] = df[df.identif.map(lambda x: x in d4['sum500'])].intensidad.sum()\n",
    "            res['sum1000'] = df[df.identif.map(lambda x: x in d4['sum1000'])].intensidad.sum()\n",
    "            return res\n",
    "        else:\n",
    "            return res\n",
    "    else:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def consulta(col, lista, hora):\n",
    "    m = 0\n",
    "    q = col.aggregate([\n",
    "     {\n",
    "         '$match': {\n",
    "             '$and': [\n",
    "                        {'identif' : { '$in': lista}},\n",
    "                        {'fecha': {'$eq': hora}}\n",
    "              ]\n",
    "        }\n",
    "    },\n",
    "    {   \n",
    "        '$group': {\n",
    "            '_id': 'A',\n",
    "            'cantidad': { '$sum' : 1 },\n",
    "            'intensidad': { '$sum' : \"$intensidad\" }\n",
    "        }}\n",
    "        ])\n",
    "    if q.alive:\n",
    "        m = list(q)[0]['intensidad']\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.44 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23715.5833333334"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time t = consulta(col2017, d4['sum1000'], hora)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "704.75"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if t.alive:\n",
    "    m = list(t)[0]['intensidad']\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prueba acceso mongo para ver tiempos (tarda mucho - descartar opción)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sin agregado (esta funciona)\n",
    "def intensidad2(coleccion, d4 , hora):\n",
    "    \"\"\"\n",
    "      input: colección donde hay qeu consultar\n",
    "             lista de estaciones de tráfico\n",
    "             e : estación que estamos enriqueciendo los datos\n",
    "             hora \n",
    "      output: nivel de intensidad\n",
    "    \"\"\"\n",
    "    res = {'sum100':0, 'sum250': 0, 'sum500':0, 'sum1000': 0}\n",
    "\n",
    "    res['sum100'] =  consulta(coleccion, d4['sum100'], hora)\n",
    "    res['sum250'] = consulta(coleccion, d4['sum250'], hora)\n",
    "    res['sum500'] = consulta(coleccion, d4['sum500'], hora)\n",
    "    res['sum1000'] = consulta(coleccion, d4['sum1000'], hora)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test\n",
    "d4 = distancias[28079004]\n",
    "fechah  = month4.fechaHora[0]\n",
    "# test\n",
    "valorunico = intensidad(col2017, d4, fechah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sum100': 704.75,\n",
       " 'sum1000': 23715.5833333334,\n",
       " 'sum250': 4658.25,\n",
       " 'sum500': 8613.0833333333}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valorunico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intensidadserie1(col, d4, serieFecha ):\n",
    "    val = serieFecha.map(lambda x: intensidad(col, d4,  x))\n",
    "    return val   # devuelve un diccionario con las 4 intensidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intensidadserie2(col, d4, serieFecha ):\n",
    "    val = serieFecha.map(lambda x: intensidad2(col, d4,  x))\n",
    "    return val   # devuelve un diccionario con las 4 intensidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.6 s\n"
     ]
    }
   ],
   "source": [
    "%time t  = intensidadserie1( col2017, d4 , month4.head(5).fechaHora )  # 85 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "# esta es peor opción\n",
    "%time t  = intensidadserie2( col2017, d4 , month4.head(5).fechaHora )  # +85 horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'sum100': 704.75, 'sum250': 4658.25, 'sum500'...\n",
       "1    {'sum100': 1417.25, 'sum250': 10590.0, 'sum500...\n",
       "2    {'sum100': 1645.25, 'sum250': 11090.0, 'sum500...\n",
       "3    {'sum100': 1288.0, 'sum250': 8625.25, 'sum500'...\n",
       "4    {'sum100': 934.75, 'sum250': 5497.25, 'sum500'...\n",
       "Name: fechaHora, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.49866666666667"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## aqui, pero tarda bastante ...  medir tiempos....   (calculo 85 horas)\n",
    "len(month4) * 17 / 5 / 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def intensidadmonth(coleccion, serieEstacion, distancias , serieFecha):\n",
    "    s = serieEstacion.map(distancias)\n",
    "  \n",
    "    valor_i  = intensidadserie(coleccion, s, serieFecha)\n",
    "    \n",
    "    \n",
    "    return valor_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'intensidadserie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-287-f8847f218d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintensidad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEstacion\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mdistancias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmonth4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfechaHora\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-286-369c3691d7c9>\u001b[0m in \u001b[0;36mintensidad\u001b[0;34m(coleccion, serieEstacion, distancias1, serieFecha)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msum500\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sum500'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mserieInten100\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mintensidadserie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoleccion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserieFecha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mserieInten1000\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintensidadserie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoleccion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserieFecha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mserieInten250\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mintensidadserie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoleccion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserieFecha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intensidadserie' is not defined"
     ]
    }
   ],
   "source": [
    "s = intensidadmonth(col, month4.Estacion, distancias, month4.fechaHora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.command_cursor.CommandCursor at 0x23107a204a8>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuevas_col = ['nivelIntensidadTrafico100', 'nivelIntensidadTrafico250',\n",
    "              'nivelIntensidadTrafico500', 'nivelIntensidadTrafico1000',]\n",
    "col = col2017\n",
    "\n",
    "\n",
    "q100 = col.aggregate([\n",
    "     {\n",
    "         '$match': {\n",
    "             '$and': [\n",
    "                        {'identif' : { '$in': d4['sum1000']}},\n",
    "                        {'fecha': {'$eq': hora}}\n",
    "              ]\n",
    "        }\n",
    "    },\n",
    "    {   \n",
    "        '$group': {\n",
    "            '_id': 'A',\n",
    "            'cantidad': { '$sum' : 1 },\n",
    "            'intensidad': { '$sum' : \"$intensidad\" }\n",
    "        }}\n",
    "        ])\n",
    "\n",
    "\n",
    "q100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### consultar mongo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True), 'trafico_timestamp'), 'trafico2017_timestamp')"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# consultas a mongo\n",
    "def open_conection():\n",
    "    client = pymongo.MongoClient('localhost',27017)\n",
    "    return client\n",
    "\n",
    "client = open_conection()\n",
    "db = client.trafico_timestamp\n",
    "col2017 = db.trafico2017_timestamp\n",
    "col2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cu = col2017.aggregate([\n",
    "     {\n",
    "         '$match': {\n",
    "             '$and': [\n",
    "                        {'identif' : { '$in':d4['sum100']}},\n",
    "                        {'fecha': {'$eq': hora}}\n",
    "              ]\n",
    "        }\n",
    "    },\n",
    "    {   \n",
    "        '$group': {\n",
    "            '_id': 28079004,\n",
    "            'cantidad_de_ordenes': { '$sum' : 1 },\n",
    "            'intensidad': { '$sum' : \"$intensidad\" }\n",
    "        }}\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cu.alive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': 28079004, 'cantidad_de_ordenes': 3, 'intensidad': 704.75}\n"
     ]
    }
   ],
   "source": [
    "for d in cu:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consulta mongo agrregado para test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.getCollection('trafico2017').aggregate([\n",
    "     {\n",
    "         '$match': {\n",
    "             '$and': [\n",
    "                        {'identif' : { '$in': ['16006', '16008', '16041']}},\n",
    "                        {'fecha': {'$eq': ISODate(\"2017-02-01T00:00:00.000Z\")}}\n",
    "              ]\n",
    "        }\n",
    "    },\n",
    "    {   \n",
    "        '$group': {\n",
    "            '_id': 'A',\n",
    "            'cantidad': { '$sum' : 1 },\n",
    "            'intensidad': { '$sum' : \"$intensidad\" }\n",
    "        }}\n",
    "        ])\n",
    "                            \n",
    "      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "284px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "485px",
    "left": "0px",
    "right": "auto",
    "top": "121px",
    "width": "303px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
